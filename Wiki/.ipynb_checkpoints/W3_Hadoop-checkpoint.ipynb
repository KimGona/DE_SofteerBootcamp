{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df78011-283f-4b07-a498-a8a353e35026",
   "metadata": {},
   "source": [
    "# W3M1: Hadoop Single-Node Cluster on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7b4f7-f91c-4ab7-a14e-c22b966cdc2a",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용해서 single-node Hadoop cluster를 세팅하면서 아파치 하둡 이해하기\n",
    "- 하둡 클러스터 설정과 도커 컨테이너화를 하며 실제적인 경험 얻기\n",
    "\n",
    "## 사전지식\n",
    "## 기능요구사항\n",
    "### Docker Image:\n",
    "- fully functional single-node Hadoop cluster 추상화하기\n",
    "- Docker container가 실행되면, 필요한 모든 Hadoop services가 자동으로 시작되어야 한다.\n",
    "- HDFS에 접근하기 위해 도커 컨테이너는 호스트 머신의 네트워크에 연결되어야 한다.\n",
    "### HDFS Operations:\n",
    "- 도커 컨테이너 안에서 HDFS와 상호작용할 수 있어야 한다.\n",
    "- create directories, upload files, and retrieve files from HDFS.\n",
    "- 파일 시스템을 모니터하기 위해 호스트 머신에서 HDFS web interface에 접근할수 있어야 한다. \n",
    "### Persistence:\n",
    "- 도커 컨테이너에 있는 하둡 데이터 디렉토리는 컨테이너가 새로시작되어도 데이터가 유지되도록 설정되어야 한다.\n",
    "- 컨테이너가 중단되었다가 다시 시작돼도 HDFS에 저장된 데이터가 그대로여야 한다. \n",
    "\n",
    "### Create and Write File in HDFS:\n",
    "- 사용자는 HDFS에서 디렉토리를 생성해야 한다. \n",
    "- 사용자는 생성된 디렉토리에서 텍스트 파일을 작성해야 한다.\n",
    "- The content of the text file should be verifiable by retrieving it from HDFS.\n",
    "### Documentation:\n",
    "- 어떻게 도커를 build하고 컨테이너를 실행하는지에 대한 instruction 작성하기\n",
    "- 컨테이너와 서비스 시작을 포함한 하둡 설정하는 단계를 포함하기\n",
    "- 기본적인 HDFS operations들도 기술하기(디렉토리 생성, 파일 업로드 등)\n",
    "\n",
    "## 프로그래밍 요구사항\n",
    "### Docker Setup:\n",
    "- 로컬에 도커 설치하기\n",
    "- 하둡환경 configure해서 도커파일 생성하기\n",
    "- single-node 하둡 클러스터로 세팅된 도커 이미지 build하기\n",
    "- 하둡에 필요한 모든 configurations과 dependencies 포함하는지 확인하기\n",
    "### Hadoop Configuration:\n",
    "- 하둡 single-node cluster위해서 core-site.xml, hdfs-site.xml, and mapred-site.xml 파일들 설정하기\n",
    "- 하둡 환경변수 설정하기\n",
    "- 도커 컨테이너 내의 HDFS namenode 틀잡기\n",
    "### Start Hadoop Services:\n",
    "- 하둡 namenode와 datanode 서비스 시작하기 (도커 컨테이너에서)\n",
    "- HDFS가 맞게 작동하는지 확인하기\n",
    "### Data Operations:\n",
    "- HDFS에서 디렉토리 생성하기\n",
    "- 로컬 파일시스템에 있는 샘플 파일 HDFS에 업로드하기\n",
    "- 파일 업로드 잘 되었는지 HDFS에서 다시 다운받아보기\n",
    "\n",
    "## 예상결과 및 동작예시\n",
    "### Running Container:\n",
    "- a single-node Hadoop cluster로 작동하는 도커 컨테이너\n",
    "- 모든하둡 서비스(네임노드, 데이터 노드 등)가 컨테이너에서 작동해야 한다.\n",
    "### HDFS Operations:\n",
    "- Create a directory in HDFS\n",
    "- Successfully upload a file from the local file system to the directory in HDFS.\n",
    "- Retrieve the uploaded file from HDFS to the local file system.\n",
    "### Accessibility:\n",
    "- Access the HDFS web interface from the host machine to verify the cluster's status and perform file system operations.\n",
    "### Submission\n",
    "- 도커파일과 하둡 클러스터 세팅에 사용된 모든 configuration file 제출하기\n",
    "- step-by-step instructions 작성한 README 파일 제출하기 (도커이미지 빌딩, 컨테이너 실행, HDFS operation 수행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d9fd7-a551-4ee1-a42b-8fae48f793f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0331ed92-cb55-4d6e-893b-2ad5286f1262",
   "metadata": {},
   "source": [
    "# W3M2a: Hadoop Multi-Node Cluster on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a38f7-865b-4f98-8451-739472de41b9",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용해서 multi-node Hadoop cluster를 세팅하면서 아파치 하둡 이해하기\n",
    "- 하둡 클러스터 설정과 도커 컨테이너화를 하며 실제적인 경험 얻기\n",
    "\n",
    "## 사전지식\n",
    "## 기능요구사항\n",
    "### Docker Images:\n",
    "- 도커 이미지는 fully functional Hadoop master and worker node를 추상화해야 한다.\n",
    "- 도커 컨테이너가 실행되면, 필요한 모든 하둡 서비스가 자동적으로 시작해야 한다.\n",
    "- master와 worker 노드 사이에 통신을 해주기 위해 컨테이너는 같은 도커 네트워크에 연결되어야 한다.\n",
    "\n",
    "### HDFS Operations:\n",
    "- 사용자는 master node의 HDFS와 상호작용할 수 있어야 한다.\n",
    "- 사용자는 디렉토리 생성, 파일 업로드, HDFS로부터 파일 가져오기를 할 수 있어야 한다.\n",
    "- 파일 시스템을 확인하기 위해 호스트 머신에서 HDFS 웹 인터페이스에 연결되어야 한다.\n",
    "\n",
    "### Cluster Operations:\n",
    "- 하둡 클러스터는 분산 저장과 분산 processing을 위해서 worker nodes를 인식하고 사용할 수 있어야한다.\n",
    "- YARN ResourceManager는 task들을 work nodes에서 실행되는 NodeManager들에게 분산시켜야 한다. \n",
    "- 클러스터는 sample MapReduce job을 성공적으로 실행해야 하고, 분산 processing을 보여주어야 한다.\n",
    "\n",
    "### Persistence:\n",
    "- 도커 컨테이너에 있는 하둡 데이터디렉토리는 컨테이너가 재시작되어도 데이터가 유지되도록 설정되어야 한다.\n",
    "- HDFS에 저장된 데이터가 컨테이너가 중단되거나 재시작되어도 남아있도록 해라\n",
    "\n",
    "### Documentation:\n",
    "- 도커 이미지를 빌드하고 컨테이너를 실행하도록 clear instructions를 작성해라\n",
    "- 컨테이너에 있는 하둡 설정과 서비스 시작을 위한 단계를 포함해라\n",
    "- 기본적은 HDFS operation을 어떻게 실행하는지 작성해라 (디렉토리 생성, 파일 업로드, MapReduce jobs 실행, file 재다운로드 등)\n",
    "- \n",
    "## 프로그래밍 요구사항\n",
    "### Docker Setup:\n",
    "- 로컬 머신에 도커를 설치해라\n",
    "- Dockerfile을 생성해서 multiple nodes를 위한 하둡 환경을 설정해라\n",
    "- 도커파일로 도커 이미지를 빌드하고 적어도 하나의 Hadoop worker node를 가지는 하둡 마스터 노드를 세팅해라\n",
    "\n",
    "### Hadoop Configuration:\n",
    "- multi-node cluster를 위해 <core-site.xml, hdfs-site.xml, mapred-site.xml, and yarn-site.xml> 파일들을 설정해라\n",
    "- master nodes와 worker nodes를 위한 하둡 환경 변수를 설정해라\n",
    "- master node에 있는 HDFS 네임노드를 정해라\n",
    "\n",
    "### Network Configuration:\n",
    "- 도커 네트워크로 세팅된 도커 컨테이너들이 다른 기기와 통신할 수 있는지 확인해라\n",
    "- 마스터 노드가 worker 노드를 인식하고 통신할 수 있도록 하둡 클러스터를 설정해라 \n",
    "\n",
    "### Start Hadoop Services:\n",
    "- 마스터 노드와 각 worker node에 있는 하둡 데이터노드 서비스에서 하둡 네임노드 서비스를 시작해라\n",
    "- HDFS가 모든 노드에서 정상적으로 실행되는지 확인해라\n",
    "- 각각의 노드들에서 YARN ResourceManager와 NodeManager services를 시작해라\n",
    "\n",
    "### Data Operations:\n",
    "- HDFS에서 디렉토리 생성하기\n",
    "- 로컬 파일 시스템에서 HDFS로 샘플 파일 업로드하기\n",
    "- 로컬에서 HDFS로 업로드가 잘 되었는지 확인하기\n",
    "- 하둡 클러스터의 기능 증명하기 위해 MapReduce job 실행해보기\n",
    "\n",
    "## 예상결과 및 동작예시\n",
    "\n",
    "### Running Containers:\n",
    "- 하둡 마스터 노드와 최소 한 워커 노드에서 도커 컨테이너 실행하기\n",
    "- 모든 하둡 서비스(namenode, datanode, ResourceManager, NodeManager, etc.)가 컨테이너들에서 실행되어야 한다. \n",
    "\n",
    "### HDFS Operations:\n",
    "- HDFS의 마스터 노드에서 디렉토리 생성하기\n",
    "- 로컬 파일 시스템에서 HDFS로 파일 업로드하기\n",
    "- 업로드된 파일 Retrieve하기\n",
    "\n",
    "### Cluster Operations:\n",
    "- 하둡 클러스터에서 sample MapReduce job 실행하기\n",
    "- 마스터와 워커 노드에서 프로세싱되며 job이 운용되는지 확인하기\n",
    "\n",
    "### Accessibility:\n",
    "- 호스트 머신에서 클러스터의 상태와 파일시스템과 job monitoring operation 작동하는지 검증하기 위해 HDFS와 YARN web interfaces에 접속하기\n",
    "\n",
    "### Submission:\n",
    "- 도커파일들과 하둡 클러스터 세팅에 사용된 다른 설정 파일들 제출하기\n",
    "- 수행 순서가 적힌 README file 제출하기(도커 이미지 빌드, 컨테이너 실행, HDFS 실행, MapReduce operation등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e329df-c5ec-419c-bef6-e3ae0db06835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6dadde6-e67f-4dbd-ad50-17b78709f735",
   "metadata": {},
   "source": [
    "# W3M2b: Understanding of Hadoop Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493ffb4-ccd2-46e9-98a2-9906551d8653",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용여 Apache Hadoop multi-node cluster를 세팅하고 설정하기\n",
    "- 최소 두개의 도커 컨테이너를 사용하고 <core-site.xml, hdfs-site.xml, mapred-site.xml, and yarn-site.xml>의 중요한 파라미터들을 설정하기\n",
    "\n",
    "## 사전지식\n",
    "### Configuration Files:\n",
    "##### core-site.xml\n",
    "- fs.defaultFS: Specifies the default file system URI.\n",
    "- hadoop.tmp.dir: Specifies the temporary directory.\n",
    "- io.file.buffer.size: Specifies the buffer size for reading/writing files.\n",
    "#### hdfs-site.xml\n",
    "- dfs.replication: Defines the default replication factor for HDFS.\n",
    "- dfs.blocksize: Specifies the default block size.\n",
    "- dfs.namenode.name.dir: Specifies the path on the local filesystem where the NameNode stores the namespace and transaction logs.\n",
    "#### mapred-site.xml\n",
    "- mapreduce.framework.name: Specifies the framework name for MapReduce.\n",
    "- mapreduce.job.tracker: Specifies the JobTracker host and port.\n",
    "- mapreduce.task.io.sort.mb: Specifies the amount of memory to use while sorting map output.\n",
    "#### yarn-site.xml\n",
    "- yarn.resourcemanager.address: The address of the ResourceManager IPC.\n",
    "- yarn.nodemanager.resource.memory-mb: Determines the amount of memory available to YARN.\n",
    "- yarn.scheduler.minimum-allocation-mb: Specifies the minimum allocation for every container request at the ResourceManager.\n",
    "## 기능요구사항\n",
    "\n",
    "Modifying Configuration Settings\n",
    "\n",
    "For each configuration file, change the identified settings to the specified values. Ensure that you follow the correct XML structure and syntax.\n",
    "### core-site.xml\n",
    "\n",
    "Change fs.defaultFS to hdfs://namenode:9000.\n",
    "Change hadoop.tmp.dir to /hadoop/tmp.\n",
    "Change io.file.buffer.size to 131072.\n",
    "### hdfs-site.xml\n",
    "\n",
    "Change dfs.replication to 2.\n",
    "Change dfs.blocksize to 134217728 (128 MB).\n",
    "Change dfs.namenode.name.dir to /hadoop/dfs/name.\n",
    "### mapred-site.xml\n",
    "\n",
    "Change mapreduce.framework.name to yarn.\n",
    "Change mapreduce.jobhistory.address to namenode:10020.\n",
    "Change mapreduce.task.io.sort.mb to 256.\n",
    "### yarn-site.xml\n",
    "\n",
    "Change yarn.resourcemanager.address to namenode:8032.\n",
    "Change yarn.nodemanager.resource.memory-mb to 8192.\n",
    "Change yarn.scheduler.minimum-allocation-mb to 1024.\n",
    "### Configuration Modification Script:\n",
    "\n",
    "The script should accept the path to the Hadoop configuration directory as an argument.\n",
    "It should back up the original configuration files before making any changes.\n",
    "The script should modify the specified settings in the XML files to the given values.\n",
    "It should handle any errors gracefully and report the status of each change.\n",
    "Backup the original configuration files.\n",
    "Modify the specified settings in the configuration files.\n",
    "Restart the Hadoop services.\n",
    "### Verification Script:\n",
    "\n",
    "The script should confirm the default file system name is set correctly by running a relevant Hadoop command and parsing the output.\n",
    "It should create a test file in HDFS and check its replication factor to verify the change.\n",
    "The script should run a simple MapReduce job and ensure it uses the YARN framework.\n",
    "It should query YARN ResourceManager to verify the total available memory for YARN.\n",
    "The script should verify the temporary directory, buffer size, block size, NameNode directory, JobTracker, sort memory buffer size, ResourceManager hostname, NodeManager memory allocation, and container minimum allocation.\n",
    "Query the Hadoop configuration to check the modified settings.\n",
    "Print the results, indicating whether each setting matches the expected value.\n",
    "Create a test file in HDFS and verify the replication factor.\n",
    "## 프로그래밍 요구사항\n",
    "\n",
    "Write a shell script or a Python program to modify the specified settings in the configuration files.\n",
    "Develop another script or program to verify the configuration changes.\n",
    "Use appropriate commands and APIs to interact with the Hadoop cluster.\n",
    "## 예상결과 및 동작예시\n",
    "\n",
    "Example Expected Outcome:\n",
    "\n",
    "### Configuration Modification Script\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e053ad3-9d77-4c01-9afe-c5a5731f2772",
   "metadata": {},
   "source": [
    "Backing up core-site.xml...\n",
    "Modifying core-site.xml...\n",
    "Backing up hdfs-site.xml...\n",
    "Modifying hdfs-site.xml...\n",
    "Backing up mapred-site.xml...\n",
    "Modifying mapred-site.xml...\n",
    "Backing up yarn-site.xml...\n",
    "Modifying yarn-site.xml...\n",
    "Stopping Hadoop DFS...\n",
    "Stopping YARN...\n",
    "Starting Hadoop DFS...\n",
    "Starting YARN...\n",
    "Configuration changes applied and services restarted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd07445-8f2e-43ab-b284-8d37a30c5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Verification Script\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d09414a7-da42-46f3-a751-4c6f31618cd8",
   "metadata": {},
   "source": [
    "PASS: ['hdfs', 'getconf', '-confKey', 'fs.defaultFS'] -> hdfs://namenode:9000\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'hadoop.tmp.dir'] -> /hadoop/tmp\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'io.file.buffer.size'] -> 131072\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.replication'] -> 2\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.blocksize'] -> 134217728\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.namenode.name.dir'] -> /hadoop/dfs/name\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.framework.name'] -> yarn\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.job.tracker'] -> namenode:9001\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.task.io.sort.mb'] -> 256\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.resourcemanager.address'] -> namenode:8032\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.nodemanager.resource.memory-mb'] -> 8192\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.scheduler.minimum-allocation-mb'] -> 1024\n",
    "PASS: Replication factor is 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548815a-f321-4555-9169-7e596df6ce60",
   "metadata": {},
   "source": [
    "Each PASS line indicates that the setting matches the expected value.\n",
    "If a setting does not match, it would print FAIL with the actual value, like this:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d99ad896-1476-48d3-9464-78a54d482926",
   "metadata": {},
   "source": [
    "FAIL: ['hdfs', 'getconf', '-confKey', 'fs.defaultFS'] -> hdfs://namenode:8020 (expected hdfs://namenode:9000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92d1db-74eb-4a4a-b933-b58c526efc02",
   "metadata": {},
   "source": [
    "### Submission:\n",
    "\n",
    "Submit 2 scripts or Python programs\n",
    "Provide the original and the changed configuration files (core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml).\n",
    "Include all the files to run testing scripts if necessary.\n",
    "Provide a README file with detailed instructions for setting up and running the scripts or programs\n",
    "## 팀 활동 요구사항\n",
    "4개의 xml files들을 살펴 보고 각 화일의 셋팅 중에 중요하거나 유용하다고 생각되는 것들을 각자 골라서 용법을 파악해 보아라 </br>\n",
    "그리고 팀과 함께 토의한 다음, 위키에 정리해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6de4-d294-4739-8a3c-7e59ff27bedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
