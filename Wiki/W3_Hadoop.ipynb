{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df78011-283f-4b07-a498-a8a353e35026",
   "metadata": {},
   "source": [
    "# W3M1: Hadoop Single-Node Cluster on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb7b4f7-f91c-4ab7-a14e-c22b966cdc2a",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용해서 single-node Hadoop cluster를 세팅하면서 아파치 하둡 이해하기\n",
    "- 하둡 클러스터 설정과 도커 컨테이너화를 하며 실제적인 경험 얻기\n",
    "\n",
    "## 사전지식\n",
    "## 기능요구사항\n",
    "### Docker Image:\n",
    "- fully functional single-node Hadoop cluster 추상화하기\n",
    "- Docker container가 실행되면, 필요한 모든 Hadoop services가 자동으로 시작되어야 한다.\n",
    "- HDFS에 접근하기 위해 도커 컨테이너는 호스트 머신의 네트워크에 연결되어야 한다.\n",
    "### HDFS Operations:\n",
    "- 도커 컨테이너 안에서 HDFS와 상호작용할 수 있어야 한다.\n",
    "- create directories, upload files, and retrieve files from HDFS.\n",
    "- 파일 시스템을 모니터하기 위해 호스트 머신에서 HDFS web interface에 접근할수 있어야 한다. \n",
    "### Persistence:\n",
    "- 도커 컨테이너에 있는 하둡 데이터 디렉토리는 컨테이너가 새로시작되어도 데이터가 유지되도록 설정되어야 한다.\n",
    "- 컨테이너가 중단되었다가 다시 시작돼도 HDFS에 저장된 데이터가 그대로여야 한다. \n",
    "\n",
    "### Create and Write File in HDFS:\n",
    "- 사용자는 HDFS에서 디렉토리를 생성해야 한다. \n",
    "- 사용자는 생성된 디렉토리에서 텍스트 파일을 작성해야 한다.\n",
    "- The content of the text file should be verifiable by retrieving it from HDFS.\n",
    "### Documentation:\n",
    "- 어떻게 도커를 build하고 컨테이너를 실행하는지에 대한 instruction 작성하기\n",
    "- 컨테이너와 서비스 시작을 포함한 하둡 설정하는 단계를 포함하기\n",
    "- 기본적인 HDFS operations들도 기술하기(디렉토리 생성, 파일 업로드 등)\n",
    "\n",
    "## 프로그래밍 요구사항\n",
    "### Docker Setup:\n",
    "- 로컬에 도커 설치하기\n",
    "- 하둡환경 configure해서 도커파일 생성하기\n",
    "- single-node 하둡 클러스터로 세팅된 도커 이미지 build하기\n",
    "- 하둡에 필요한 모든 configurations과 dependencies 포함하는지 확인하기\n",
    "### Hadoop Configuration:\n",
    "- 하둡 single-node cluster위해서 core-site.xml, hdfs-site.xml, and mapred-site.xml 파일들 설정하기\n",
    "- 하둡 환경변수 설정하기\n",
    "- 도커 컨테이너 내의 HDFS namenode 틀잡기\n",
    "### Start Hadoop Services:\n",
    "- 하둡 namenode와 datanode 서비스 시작하기 (도커 컨테이너에서)\n",
    "- HDFS가 맞게 작동하는지 확인하기\n",
    "### Data Operations:\n",
    "- HDFS에서 디렉토리 생성하기\n",
    "- 로컬 파일시스템에 있는 샘플 파일 HDFS에 업로드하기\n",
    "- 파일 업로드 잘 되었는지 HDFS에서 다시 다운받아보기\n",
    "\n",
    "## 예상결과 및 동작예시\n",
    "### Running Container:\n",
    "- a single-node Hadoop cluster로 작동하는 도커 컨테이너\n",
    "- 모든하둡 서비스(네임노드, 데이터 노드 등)가 컨테이너에서 작동해야 한다.\n",
    "### HDFS Operations:\n",
    "- Create a directory in HDFS\n",
    "- Successfully upload a file from the local file system to the directory in HDFS.\n",
    "- Retrieve the uploaded file from HDFS to the local file system.\n",
    "### Accessibility:\n",
    "- Access the HDFS web interface from the host machine to verify the cluster's status and perform file system operations.\n",
    "### Submission\n",
    "- 도커파일과 하둡 클러스터 세팅에 사용된 모든 configuration file 제출하기\n",
    "- step-by-step instructions 작성한 README 파일 제출하기 (도커이미지 빌딩, 컨테이너 실행, HDFS operation 수행)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b215c",
   "metadata": {},
   "source": [
    "#### Hadoop Components\n",
    "- HDFS: Storage Layer\n",
    "- Hadoop Yarn: Resource Management Layer\n",
    "- Hadoop MapReduce: Application Layer\n",
    "\n",
    "#### 하둡 아키텍처\n",
    "- 마스터 노드(네임노드, 리소스 매니저)\n",
    "- 슬레이브 노드(데이터노드, 노드 매니저, 맵, 리듀스)\n",
    "\n",
    "#### Assumptions and Goals of HDFS\n",
    "- Hardware Failure\n",
    "- Streaming Data Access\n",
    "- Large Data sets\n",
    "- Simple Coherency Model\n",
    "- Moving Computation is Cheaper than Moving Data\n",
    "- Portability across Heterogeneous Hardware and Software Platforms\n",
    "\n",
    "네임노드(in Master node)는 파일시스템의 메타데이터를 저장한다.  \n",
    "어플리케이션 매니저(in Master node)  \n",
    "데이터 노드(in Master node)는 실제 데이터를 저장한다.(네임노드 지시에 따라 동작함)  \n",
    "어플리케이션 마스터(in Slave node): 리소스매니절  \n",
    "\n",
    "\n",
    "- YARN: 리소스 관리와 잡 스케줄링을 분리함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d9fd7-a551-4ee1-a42b-8fae48f793f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0331ed92-cb55-4d6e-893b-2ad5286f1262",
   "metadata": {},
   "source": [
    "# W3M2a: Hadoop Multi-Node Cluster on Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a38f7-865b-4f98-8451-739472de41b9",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용해서 multi-node Hadoop cluster를 세팅하면서 아파치 하둡 이해하기\n",
    "- 하둡 클러스터 설정과 도커 컨테이너화를 하며 실제적인 경험 얻기\n",
    "\n",
    "## 사전지식\n",
    "## 기능요구사항\n",
    "### Docker Images:\n",
    "- 도커 이미지는 fully functional Hadoop master and worker node를 추상화해야 한다.\n",
    "- 도커 컨테이너가 실행되면, 필요한 모든 하둡 서비스가 자동적으로 시작해야 한다.\n",
    "- master와 worker 노드 사이에 통신을 해주기 위해 컨테이너는 같은 도커 네트워크에 연결되어야 한다.\n",
    "\n",
    "### HDFS Operations:\n",
    "- 사용자는 master node의 HDFS와 상호작용할 수 있어야 한다.\n",
    "- 사용자는 디렉토리 생성, 파일 업로드, HDFS로부터 파일 가져오기를 할 수 있어야 한다.\n",
    "- 파일 시스템을 확인하기 위해 호스트 머신에서 HDFS 웹 인터페이스에 연결되어야 한다.\n",
    "\n",
    "### Cluster Operations:\n",
    "- 하둡 클러스터는 분산 저장과 분산 processing을 위해서 worker nodes를 인식하고 사용할 수 있어야한다.\n",
    "- YARN ResourceManager는 task들을 work nodes에서 실행되는 NodeManager들에게 분산시켜야 한다. \n",
    "- 클러스터는 sample MapReduce job을 성공적으로 실행해야 하고, 분산 processing을 보여주어야 한다.\n",
    "\n",
    "### Persistence:\n",
    "- 도커 컨테이너에 있는 하둡 데이터디렉토리는 컨테이너가 재시작되어도 데이터가 유지되도록 설정되어야 한다.\n",
    "- HDFS에 저장된 데이터가 컨테이너가 중단되거나 재시작되어도 남아있도록 해라\n",
    "\n",
    "### Documentation:\n",
    "- 도커 이미지를 빌드하고 컨테이너를 실행하도록 clear instructions를 작성해라\n",
    "- 컨테이너에 있는 하둡 설정과 서비스 시작을 위한 단계를 포함해라\n",
    "- 기본적은 HDFS operation을 어떻게 실행하는지 작성해라 (디렉토리 생성, 파일 업로드, MapReduce jobs 실행, file 재다운로드 등)\n",
    "- \n",
    "## 프로그래밍 요구사항\n",
    "### Docker Setup:\n",
    "- 로컬 머신에 도커를 설치해라\n",
    "- Dockerfile을 생성해서 multiple nodes를 위한 하둡 환경을 설정해라\n",
    "- 도커파일로 도커 이미지를 빌드하고 적어도 하나의 Hadoop worker node를 가지는 하둡 마스터 노드를 세팅해라\n",
    "\n",
    "### Hadoop Configuration:\n",
    "- multi-node cluster를 위해 <core-site.xml, hdfs-site.xml, mapred-site.xml, and yarn-site.xml> 파일들을 설정해라\n",
    "- master nodes와 worker nodes를 위한 하둡 환경 변수를 설정해라\n",
    "- master node에 있는 HDFS 네임노드를 정해라\n",
    "\n",
    "### Network Configuration:\n",
    "- 도커 네트워크로 세팅된 도커 컨테이너들이 다른 기기와 통신할 수 있는지 확인해라\n",
    "- 마스터 노드가 worker 노드를 인식하고 통신할 수 있도록 하둡 클러스터를 설정해라 \n",
    "\n",
    "### Start Hadoop Services:\n",
    "- 마스터 노드와 각 worker node에 있는 하둡 데이터노드 서비스에서 하둡 네임노드 서비스를 시작해라\n",
    "- HDFS가 모든 노드에서 정상적으로 실행되는지 확인해라\n",
    "- 각각의 노드들에서 YARN ResourceManager와 NodeManager services를 시작해라\n",
    "\n",
    "### Data Operations:\n",
    "- HDFS에서 디렉토리 생성하기\n",
    "- 로컬 파일 시스템에서 HDFS로 샘플 파일 업로드하기\n",
    "- 로컬에서 HDFS로 업로드가 잘 되었는지 확인하기\n",
    "- 하둡 클러스터의 기능 증명하기 위해 MapReduce job 실행해보기\n",
    "\n",
    "## 예상결과 및 동작예시\n",
    "\n",
    "### Running Containers:\n",
    "- 하둡 마스터 노드와 최소 한 워커 노드에서 도커 컨테이너 실행하기\n",
    "- 모든 하둡 서비스(namenode, datanode, ResourceManager, NodeManager, etc.)가 컨테이너들에서 실행되어야 한다. \n",
    "\n",
    "### HDFS Operations:\n",
    "- HDFS의 마스터 노드에서 디렉토리 생성하기\n",
    "- 로컬 파일 시스템에서 HDFS로 파일 업로드하기\n",
    "- 업로드된 파일 Retrieve하기\n",
    "\n",
    "### Cluster Operations:\n",
    "- 하둡 클러스터에서 sample MapReduce job 실행하기\n",
    "- 마스터와 워커 노드에서 프로세싱되며 job이 운용되는지 확인하기\n",
    "\n",
    "### Accessibility:\n",
    "- 호스트 머신에서 클러스터의 상태와 파일시스템과 job monitoring operation 작동하는지 검증하기 위해 HDFS와 YARN web interfaces에 접속하기\n",
    "\n",
    "### Submission:\n",
    "- 도커파일들과 하둡 클러스터 세팅에 사용된 다른 설정 파일들 제출하기\n",
    "- 수행 순서가 적힌 README file 제출하기(도커 이미지 빌드, 컨테이너 실행, HDFS 실행, MapReduce operation등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e329df-c5ec-419c-bef6-e3ae0db06835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6dadde6-e67f-4dbd-ad50-17b78709f735",
   "metadata": {},
   "source": [
    "# W3M2b: Understanding of Hadoop Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493ffb4-ccd2-46e9-98a2-9906551d8653",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 도커를 사용여 Apache Hadoop multi-node cluster를 세팅하고 설정하기\n",
    "- 최소 두개의 도커 컨테이너를 사용하고 <core-site.xml, hdfs-site.xml, mapred-site.xml, and yarn-site.xml>의 중요한 파라미터들을 설정하기\n",
    "\n",
    "## 사전지식\n",
    "### Configuration Files:\n",
    "##### core-site.xml\n",
    "- fs.defaultFS: default file system URI을 명시\n",
    "- hadoop.tmp.dir: temporary directory를 명시\n",
    "- io.file.buffer.size: reading/writing files 의 버퍼 사이즈를 명시\n",
    "\n",
    "#### hdfs-site.xml\n",
    "- dfs.replication: HDFS 디폴트 replication factor 정의\n",
    "- dfs.blocksize: 디폴트 block size 명시\n",
    "- dfs.namenode.name.dir: NameNode 가 저장하고 있는 namespace와 transaction logs가 있는 로컬 파일 시스템 경로를 명시\n",
    "\n",
    "#### mapred-site.xml\n",
    "- mapreduce.framework.name: 맵리듀스의 framework 이름 명시\n",
    "- mapreduce.job.tracker: JobTracker host와 port 명시\n",
    "- mapreduce.task.io.sort.mb: 맵(map) 출력 데이터를 정렬할 때 사용할 메모리의 양 명시\n",
    "\n",
    "#### yarn-site.xml\n",
    "- yarn.resourcemanager.address: ResourceManager IPC의 주소\n",
    "- yarn.nodemanager.resource.memory-mb: YARM에 사용가능한 memory 양 결정\n",
    "- yarn.scheduler.minimum-allocation-mb: ResourceManager에서 각 컨테이너 요청에 대해 할당되는 최소 자원 명시\n",
    "\n",
    "## 기능요구사항 : 설정 값들 아래 값들로 수정하기\n",
    "### core-site.xml\n",
    "- Change fs.defaultFS to hdfs://namenode:9000.\n",
    "- Change hadoop.tmp.dir to /hadoop/tmp.\n",
    "- Change io.file.buffer.size to 131072.\n",
    "### hdfs-site.xml\n",
    "- Change dfs.replication to 2.\n",
    "- Change dfs.blocksize to 134217728 (128 MB).\n",
    "- Change dfs.namenode.name.dir to /hadoop/dfs/name.\n",
    "### mapred-site.xml\n",
    "- Change mapreduce.framework.name to yarn.\n",
    "- Change mapreduce.jobhistory.address to namenode:10020.\n",
    "- Change mapreduce.task.io.sort.mb to 256.\n",
    "### yarn-site.xml\n",
    "- Change yarn.resourcemanager.address to namenode:8032.\n",
    "- Change yarn.nodemanager.resource.memory-mb to 8192.\n",
    "- Change yarn.scheduler.minimum-allocation-mb to 1024.\n",
    "### Configuration Modification Script:\n",
    "- 스크립트는 인자로 받은 하둡 설정 디렉토리를 경로로 받아야 한다.\n",
    "- 수정하기 전에 original 설정 파일들을 백업해 두어야 한다.\n",
    "- 스크립트는 주어진 값에 따라 xml 파일안의 값들을 수정해야 한다.\n",
    "- 에러들을 잘 처리하고 각 변화에 대한 상태를 기술해라\n",
    "- original 설정 파일들을 백업해라\n",
    "- 설정 파일들의 특정 값들을 수정해라\n",
    "- 하둡 서비스를 재시작해라\n",
    "\n",
    "### Verification Script:\n",
    "- 적절한 Hadoop 명령어를 실행하여 기본 파일 시스템 이름이 올바르게 설정되었는지 확인하고 출력 결과를 파싱하여 설정이 정확한지 확인한다.\n",
    "- HDFS에 테스트 파일을 생성하고 복제 계수(Replication Factor)를 확인하여 설정(수정한 것_이 올바르게 적용되었는지 검증한다.\n",
    "- 간단한 MapReduce 작업을 실행하고, 해당 작업이 YARN 프레임워크를 사용했는지 확인한다.\n",
    "- YARN ResourceManager를 쿼리하여 YARN에 할당된 총 사용 가능 메모리를 확인한다.\n",
    "- 설정들이 올바르게 적용되었는지 확인한다.(temporary directory, buffer size, block size, NameNode directory, JobTracker, sort memory buffer size, ResourceManager hostname, NodeManager memory allocation, and container minimum allocation)\n",
    "- Hadoop 설정값을 쿼리하여 변경된 설정들이 제대로 적용되었는지 확인합니다.\n",
    "- 결과 출력하고 각 설정이 기대한 값과 일치하는지 확인해라\n",
    "- HDFS에 테스트 파일을 생성하고, 복제 계수를 확인하여 설정이 올바르게 반영되었는지 검증합니다.\n",
    "\n",
    "## 프로그래밍 요구사항\n",
    "- 셸 스크립트나 파이썬 프록램을 작성해서 설정 파일들의 특정 값들을 수정해라\n",
    "- 다른 스크립트나 프로그램을 만들어서 수정된 설정 값들을 증명해라\n",
    "- 적절한 커맨드와 API들을 사용해서 하둡 클러스터와 상호작용해라\n",
    "\n",
    "## 예상결과 및 동작예시\n",
    "### Configuration Modification Script"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e053ad3-9d77-4c01-9afe-c5a5731f2772",
   "metadata": {},
   "source": [
    "Backing up core-site.xml...\n",
    "Modifying core-site.xml...\n",
    "Backing up hdfs-site.xml...\n",
    "Modifying hdfs-site.xml...\n",
    "Backing up mapred-site.xml...\n",
    "Modifying mapred-site.xml...\n",
    "Backing up yarn-site.xml...\n",
    "Modifying yarn-site.xml...\n",
    "Stopping Hadoop DFS...\n",
    "Stopping YARN...\n",
    "Starting Hadoop DFS...\n",
    "Starting YARN...\n",
    "Configuration changes applied and services restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354618e-3cee-43ec-93fa-4dac9ac1d9a3",
   "metadata": {},
   "source": [
    "### Verification Script"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d09414a7-da42-46f3-a751-4c6f31618cd8",
   "metadata": {},
   "source": [
    "PASS: ['hdfs', 'getconf', '-confKey', 'fs.defaultFS'] -> hdfs://namenode:9000\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'hadoop.tmp.dir'] -> /hadoop/tmp\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'io.file.buffer.size'] -> 131072\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.replication'] -> 2\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.blocksize'] -> 134217728\n",
    "PASS: ['hdfs', 'getconf', '-confKey', 'dfs.namenode.name.dir'] -> /hadoop/dfs/name\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.framework.name'] -> yarn\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.job.tracker'] -> namenode:9001\n",
    "PASS: ['hadoop', 'getconf', '-confKey', 'mapreduce.task.io.sort.mb'] -> 256\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.resourcemanager.address'] -> namenode:8032\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.nodemanager.resource.memory-mb'] -> 8192\n",
    "PASS: ['yarn', 'getconf', '-confKey', 'yarn.scheduler.minimum-allocation-mb'] -> 1024\n",
    "PASS: Replication factor is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548815a-f321-4555-9169-7e596df6ce60",
   "metadata": {},
   "source": [
    "Each PASS line indicates that the setting matches the expected value.\n",
    "If a setting does not match, it would print FAIL with the actual value, like this:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d99ad896-1476-48d3-9464-78a54d482926",
   "metadata": {},
   "source": [
    "FAIL: ['hdfs', 'getconf', '-confKey', 'fs.defaultFS'] -> hdfs://namenode:8020 (expected hdfs://namenode:9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92d1db-74eb-4a4a-b933-b58c526efc02",
   "metadata": {},
   "source": [
    "### Submission:\n",
    "- 2 scripts or Python programs 제출하기\n",
    "- 원래 설정 파일과 수정한 설정 파일 제출하기(core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml)\n",
    "- 테스트 스크립트 실행하는 데 필요한 모든 파일들 포함하기\n",
    "- 스크립트나 프로그램 셋업하고 실행하는 데 필요한 자세한 instruction을 작성한 README 파일 제출하기\n",
    "\n",
    "## 팀 활동 요구사항\n",
    "4개의 xml files들을 살펴 보고 각 화일의 셋팅 중에 중요하거나 유용하다고 생각되는 것들을 각자 골라서 용법을 파악해 보아라 </br>\n",
    "그리고 팀과 함께 토의한 다음, 위키에 정리해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6de4-d294-4739-8a3c-7e59ff27bedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
