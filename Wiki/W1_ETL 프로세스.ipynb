{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390c4f8c-136b-46f9-a99d-bb5bb528d75c",
   "metadata": {},
   "source": [
    "## 1월 6일"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fd2b694-9042-4ee1-8813-7f2ef4873be3",
   "metadata": {},
   "source": [
    "ETL\n",
    "1. Extract(추출): 소스 데이터베이스에서 관련 데이터 추출\n",
    "2. Transfer(변환): 분석에 더 적합한 형식으로 데이터 변환\n",
    "3. Load(적재): 데이터를 대상 데이터베이스에 로드"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e97f60e1-23a5-4623-9780-2ca9069dcafe",
   "metadata": {},
   "source": [
    "BeautifulSoup의 첫 번째 매개변수는 HTML 문서나 HTML 형식의 텍스트이어야 하고, URL이 아닌 HTML 문자열이어야 합니다. \n",
    "현재 코드에서는 URL을 직접 전달하고 있습니다. \n",
    "만약 해당 URL의 HTML을 분석하려면, requests와 같은 라이브러리로 먼저 HTML 내용을 가져온 다음에 BeautifulSoup으로 처리해야 합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb9afcc1-904e-4c83-9bde-d9c2d75a1a2f",
   "metadata": {},
   "source": [
    "W1M3 과제 내용(1월 6일 작성)\n",
    "\n",
    "1. 위키피디아에 있는 GDP 테이블을 크롤링 해오기 \n",
    "\n",
    "2. 추출한 정보는 가공 후 - Pandas 사용하기\n",
    "\n",
    "(GDP 높은 국가들이 먼저 나오도록, GDP의 단위는 1B USD이고 소수점 2자리 까지만 표시하기)\n",
    "+ 정보가 갱신되더라도 해당 코드를 재사용해서 정보를 얻을 수 있어야 한다.\n",
    "표에서 0 3개 빼야 million ->billion\n",
    "\n",
    "‘Countries_by_GDP.json’으로 저장하기\n",
    "\n",
    "3. 모든 처리 과정을 ‘etl_project_log.txt’파일에 기록하기\n",
    "log는 \"time, log\" 형식으로 기록하세요. \n",
    "시간은 'Year-Monthname-Day-Hour-Minute-Second' 포맷에 맞게 표시하세요\n",
    "\n",
    "Logging \n",
    "pycountry_convert\n",
    "\n",
    "4.해당 작업은 ‘etl_project_gdp.py’ 파일에 작성하기 \n",
    "주석 달아서 설명 추가\n",
    "함수 만들어서 가독성과 재사용성 높이기\n",
    "\n",
    "5. 테이블로 시각화하기(출력) Pandas 사용하기\n",
    " \n",
    "GDP가 100B USD 이상이 되는 국가만 구해서 화면에 출력하기\n",
    "각 Region별로 top5 국가의 GDP평균을 구해서 화면에 출력하기\n",
    "\n",
    "<추가 요구사항>\n",
    "6. 추출한 데이터를 ‘World_Economies.db’에 저장하기\n",
    "Sqlite3 사용,\n",
    "테이블명: Countreis_by_GDP\n",
    "Country, GDP_USD_billion 컬럼 반드시 넣기\n",
    "\n",
    "7. 필요한 모든 작업을 수행하는 ‘etl_project_gdp_with_sql.py’ 작성하기\n",
    "\n",
    "8. Sql 쿼리 사용해서 화면 출력하기\n",
    "GDP가 100B USD 이상이 되는 국가만을 구해서 화면에 출력\n",
    "각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력\n",
    "\n",
    "<팀활동>\n",
    "- Wikipedia 페이지가 아닌, IMF 홈페이지에서 직접 데이터를 가져오는 방법은 없을까? 어떻게 하면 될까?\n",
    "\n",
    "- 만약 데이터가 갱신되면 과거의 데이터는 어떻게 되어야 할까? 과거의 데이터를 조회하는 게 필요하다면 ETL프로세스를 어떻게 변경해야 할까?\n",
    "\n",
    "<추추가>\n",
    "- Raw 데이터 양이 압도적으로 많다면? Raw 데이터를 Transform하는 데 시간이 아주 오래 걸린다면  ETL 처리 코드를 어떻게 작성하는 것이 효과적, 효율적일지 검토해보기\n",
    "\n",
    "\n",
    "모르겠는 것\n",
    "로그 기록 어떻게 해야 하나? 어떤 상황에서 로그 기록 해야 하나?? - 1/7 해결\n",
    "추출할때: BeutifulSoup 사용\n",
    "변환할때(가공할 때??): Pandas 사용 \n",
    "로드 할 때: df->db로 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73ebe8-a835-4697-8bc4-e1435658ed8f",
   "metadata": {},
   "source": [
    "## 1월 7일"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a26b20f8-1fe1-4156-854e-c6a3d44a9f38",
   "metadata": {},
   "source": [
    "기본기능 1,2,3,4 완료\n",
    "시각화(5번)는 하나만 완료\n",
    "추가 요구사항 6은 완료 7,8 은 진행 중\n",
    "\n",
    "M3의 기본적인 과정과 기능은 구현했지만 Region 데이터 추가하고 연동하는 것은 아직 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abea38-f4f7-4a9d-be2c-e0620bec8e83",
   "metadata": {},
   "source": [
    "## 1월 8일"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d55df150-0ab7-4dc5-a383-f0ed4600fcab",
   "metadata": {},
   "source": [
    "M3) Region 데이터와 연결하는 데이터 처리 SQL 풀이"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad594f28-9759-4bb8-9e76-de544af30024",
   "metadata": {},
   "source": [
    "미션: 각 Region별로 top5 국가의 GDP 평균을 구해서 화면에 출력해야 합니다.\n",
    "- 각 Region별로 GDP 순서대로 랭킹 매기기\n",
    "-> 그룹별 상위 5개씩 묶어서 그룹명, 평균값 출력하기\n",
    "\n",
    "SELECT Region, ROUND(AVG(GDP), 2) AS Avg_Top5_GDP\n",
    "                    FROM ( SELECT Region, GDP, ROW_NUMBER() OVER (PARTITION BY Region ORDER BY GDP DESC) AS rank\n",
    "                    FROM Countries_by_GDP\n",
    "                    WHERE REGION IS NOT NULL\n",
    "                )\n",
    "                WHERE rank <= 5\n",
    "                GROUP BY Region; "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b0a20ae-7b00-406a-926c-1794a16efcde",
   "metadata": {},
   "source": [
    "M3) Region 데이터 연결하는 pandas code\n",
    "    # GDP 기준으로 내림차순 정렬\n",
    "    sorted_df = df.sort_values(by=\"GDP_USD_billion\", ascending=False)\n",
    "\n",
    "    # 각 Region별 상위 5개 국가 선택\n",
    "    top5_per_region = (\n",
    "        sorted_df.groupby(\"Region\", group_keys=False)\n",
    "                .apply(lambda x: x.nlargest(5, \"GDP_USD_billion\"))\n",
    "    )\n",
    "\n",
    "    # Region별 상위 5개 국가의 GDP 평균 계산\n",
    "    region_top5_avg_gdp = top5_per_region.groupby(\"Region\")[\"GDP_USD_billion\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632850ee-f6be-4ca1-8ba2-5458f183f5da",
   "metadata": {},
   "source": [
    "## 팀 활동 및 생각해볼 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91841344-a7fb-43e9-85a3-5afd4f2f9625",
   "metadata": {},
   "source": [
    "### 팀 활동 요구사항\n",
    "wikipeida 페이지가 아닌, IMF 홈페이지에서 직접 데이터를 가져오는 방법은 없을까요? 어떻게 하면 될까요?\n",
    "- IMF 페이지에도 테이블 형식으로 있다면, wikipedia에서 데이터를 가져온 것처럼 html 파싱해서 가져오기\n",
    "- 파일 다운로드 받을 수 있다면 파일 다운받아서 (csv파일 등) 사용하기\n",
    "- 다른 어떤 형태로 있을 수 있지??… 텍스트..??,, 아니면 반응형 웹??형태라면 뜯어볼 수 있을까..???\n",
    "- API도 있음\n",
    "\n",
    "만약 데이터가 갱신되면 과거의 데이터는 어떻게 되어야 할까요? 과거의 데이터를 조회하는 게 필요하다면 ETL 프로세스를 어떻게 변경해야 할까요?\n",
    "- 주기적으로 데이터를 저장(백업)\n",
    "- Or 이전에 저장해놓은 데이터와 달라지면 다시 저장하기(용량이 너무 크면 한계가 있을 것 같다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a54ca5-2867-4872-a496-28ae1a02202a",
   "metadata": {},
   "source": [
    "### 여러분이 작성한 ETL 처리 코드를 아래 가정을 가지고 다시 리뷰해 보세요.\n",
    "\n",
    "\t1. raw 데이터의 양이 압도적으로 많다면?\n",
    "\n",
    "클라우드에, 데이터베이스에, 병렬 처리 등을 통해서 저장하기</br>\n",
    "(데이터Lake - 정형, 비정형, 반정형의 모든 데이터 저장할 수 있다.)</br>\n",
    "스파크 등 빅데이터 효과적으로 다룰 수 있는 툴을 사용한다\n",
    "\n",
    "*** 코드 개선 적으로도 stream false 하면 메모리 너무 크면 메모리 초과 난다 </br>\n",
    "Stream true 하면 본인이 설정한 데이터 크기만큼 잘라서 가져온다. -> 오류 안남 ***\n",
    "\n",
    "\t2. raw 데이터를 Transform 하는데 시간이 아주 오래 걸린다면?\n",
    "병렬 처리를 한다. \n",
    "Pool이라는 Python 라이브러리가 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e265ccc-3382-4f34-978d-efc7432f3473",
   "metadata": {},
   "source": [
    "### 여러분이 작성한 코드를 ETL로 잘 나눠 보세요. 정의대로 잘 나눠지나요?\n",
    "\n",
    "#### 여러분이 작성한 코드는 ETL 각각의 단계가 독립적으로 구분되어 작동하나요?\t\n",
    "#### 만약 ETL에서 각각의 과정을 별도로 프로세스로 처리한다면 어떻게 코드를 변경해야 할까요?\n",
    "#### 병렬/분산 처리를 한다면 대응 가능한 코드인가요?\n",
    "#### 대용량 데이터를 처리하는 과정에서 에러가 난다면 어떻게 해야 할까요?\n",
    "\n",
    "E,T,L으로는 코드를 잘 나눈 것 같은데 현재의 코드로는 병렬/ 분산 처리는 불가하다\n",
    "\n",
    "#### “ETL과정에 대해 생각한 정의가 팀원과 달랐다. 웹을 크롤링해와서 데이터프레임으로 만드는 과정 자체를 Transform으로 보아야할까? 그럼 데이터프레임은 원시데이터가 아닌것일까?” ==> 여러분들은 어떻게 생각하세요?\n",
    "\t\t\n",
    "dataframe은 데이터를 보기 좋도록 활용하는 툴이라고 생각한다.</br>\n",
    "웹을 크롤링 해와서 데이터 프레임으로 만드는 과정은 개인적으로 transform이라고 생각하지 않음. </br>Dataframe 의 기능들 이용해서 컬럼/데이터 값 변경 등을 하는 경우엔 transform 과정이라고 생각합니다,,,,</br>\n",
    "\t\t\n",
    "#### “추출 (Extract)한 정보는 'Countries_by_GDP.json'라는 이름의 JSON 화일 포맷으로 저장해야 합니다.” ==> 추출한 데이터를 저장했을 때 어떤 이점이 있을까요?\n",
    "- 가공하기 전 데이터를 한 번 저장함으로써 앞으로의 데이터 변환 가능성을 열어둘 수 있다. 데이터를 가지고 하고자 하는 작업이 항상 같지 않을 것이기 때문임\n",
    "\n",
    "- 오류 방지 기능도 있다. 추출한 후, 데이터를 transform 하는 과정에서 오류가 날 수 있다. 추출한 데이터를 저장해 좋으면 다시 추출할 필요 없음\n",
    "\n",
    "- 여러 소스에서 데이터를 뽑아올 수도 있다. -> raw 데이터를 저장할 필요 있고, 병렬 분산 처리도 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e4e32-80bc-4674-b4d4-8e7391d02acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
