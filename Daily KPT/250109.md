## Review

#### 현실의 데이터가 절대로 친절하지 않음. 데이터에서 어떻게 비즈니스적인, 경제적인 가치를 도출해 낼 것인지 항상 생각해야 한다!

“Data Product” - 반복적으로 이용할 만큼 가치가 있을 것!!</br>
Raw Data를 Transform 하는 과정에서 금전적 가치가 있어야 함!!</br>
Data Product: Data + Domain + Access + Data Product Catalog</br>

< ETL 과정> </br>
E: 온라인 상의 자료(로컬 자료 거의 없음) 취합할 때 에러가 날 가능성 높다! 오류나면 어떻게 처리할 지도 생각해야 한다.</br>
T: Staging Area 라는 임시 공간에서 처리 - ETL 과정에서  필요한 자원이다. </br>
Transform 과정 중간에서도 오류가 발생한다면 어떻게 대처할 것인지도 생각해야 한다. </br>
L: DB 에 올리는 이유: 효율적으로, 빠르게 일을 하기 위해서</br>
*** DB 가격이 싸져서 요즘은 ELT 방식으로 많이 작업한다. (일단 데이터 올리고 시작!)</br>

데이터가 많아지면 병렬처리 해야한다. Spark 등 병렬 처리해주는 프로그램도 존재함.</br>
모듈화 해야 한다. -> 유지보수성 좋아야 함.</br>

판다스 왜 사용하냐? 쓰기 쉽다(->유지보수 측면에서도), 성능이 좋음 </br>
각 과정별로 추상화가 되어야 한다. </br>
판다스에 넣고 빼는 것도 비용(시간, 돈, 메모리 등 다 포함) 이다!!</br>



## Keep
기능별로 함수만들기(모듈화)</br>

## Problem
raw 데이터를 어떤 절차를 거쳐 저장할 것인지 조원이 작성한 코드가 다 달랐다. </br>
1) html -> table 추출한 것을 pandas로 변환한 후 json 파일로 저장할 수도 있고, </br>
2) html -> table 추출해서 필요한 데이터를 list에 추가->dict로 묶어서 json 파일로 저장할 수도 있다.</br>
1번 방식으로는 두 칸에 하나의 값('-')만 들어있는 경우에도 빼먹는 칸의 값 없이 json 파일로 잘 저장이 되었고, 2번 방식으로는 두 칸에 하나의 값만 있는 경우 값이 채워지는 것이 아니라 하나의 값으로만 저장이 되어, 따로 처리를 하지 않는 이상, 데이터의 정합성에 문제가 생겨서 데이터를 날렸다. </br>
판다스를 활용하여 데이터를 처리할 때, 데이터의 일관성이 더 잘 유지된다는 생각이 듦과 동시에, 만약 데이터가 너무 크다면 pandas 이용에 문제가 생길 수도 있다는 생각이 들었다. </br>
상황에 맞게 툴을 잘 사용하는 사람이 되고 싶다.</br>

오류가 나면 어떻게 처리해야 할까??</br>
단순 try catch 구문을 쓰면 될지, 혹은 다른 방법이 있는지 찾아보아야겠다.</br>


## Try
주어진 과제를 해결하는 것에 그치지 말고 생각하기,,,!! 앞으로 프로젝트를 진행할 때에도 마찬가지!! </br>


